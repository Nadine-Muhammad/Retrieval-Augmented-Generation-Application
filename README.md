 A Retrieval-Augmented Generation (RAG)  that supports choice from three language models—Phi 3.5, Falcon 7B, and Llama 3— within the framework. Using technical articles and short stories
 as sources, we evaluate the models based on response accuracy and relevance.
 
Some techniques were explored like: Chunking, query translation, and retrieval methods to optimize the RAG pipeline and identify the best model configuration for generating high-quality, contextually relevant responses.
![image](https://github.com/user-attachments/assets/5299c44b-9366-4f7c-86e9-78849bce1d7b)
